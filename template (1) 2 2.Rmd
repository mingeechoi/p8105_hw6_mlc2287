---
title: "Homework 6"
author: "Mingee Choi"
date: 12/1/2022
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(broom)
library(patchwork)
library(modelr)
library(mgcv)

set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 2

Create city_state variable and binary variable indicating whether homicide is solved. Omit certain cities and Tulsa, AL. Limit analysis for whom victim_race is white or black. Make sure victim_age is numeric.

```{r}
homicide_data=
  read_csv("./data/homicide-data.csv")%>%
  janitor::clean_names()%>%
  mutate(reported_date = lubridate::ymd(reported_date))%>%
  drop_na(reported_date)

homicide_df=
homicide_data%>%
  mutate(city_state= str_c(city, state, sep=",")
  )%>%
  select(uid,city_state,everything())%>%
  group_by(city_state)%>%
  mutate(solved = case_when(disposition == "Closed by arrest" ~ 1,
                            disposition ==  "Closed without arrest" ~ 0,
                            disposition == "Open/No arrest" ~ 0),
         victim_age = as.numeric(victim_age),
         victim_race = as.factor(victim_race)) %>% 
  filter(city_state != "Dallas,TX", 
         city_state != "Phoenix,AZ", 
         city_state != "Kansas City,MO",
         city_state != "Tulsa,AL",
         victim_race %in% c("Black", "White")) %>% 
  select(city_state, solved, victim_age, victim_race, victim_sex)

homicide_df
```

Fit logistic regression with resolved vs unresolved as outcome and victim and age, sex, and race, as predictors.Save glm as R object.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore,MD")

baltimore_glm=
  baltimore_df%>%
  glm(solved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 

save(baltimore_glm, file="baltimore_glm.RData")
```

 Apply broom: tidy to object and obtain estimate and confidence interval of adjusted OR for solving homicides comparing male to female victims, keeping all other variable fixed.
 
```{r}
baltimore_glm%>%
 broom::tidy() %>% 
  mutate(OR = exp(estimate),
         lower_ci = exp(estimate - 1.96*std.error),
         upper_ci = exp(estimate + 1.96*std.error)) %>% 
  select(term, log_OR = estimate, OR, p.value, lower_ci, upper_ci) %>% 
  knitr::kable(digits = 3)
```

Run glm for each cities in dataset and extract adjusted OR and CI for solving homicides comparing male to female victims. Unnest.

```{r}
cities_glm=
  homicide_df%>%
  nest(data = -city_state) %>%
  mutate( 
    models = map(.x = data, ~glm(solved ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())), 
    results = map(models, broom::tidy)) %>%  
  select(city_state, results) %>% 
  unnest(results) %>%
  mutate(OR = exp(estimate),
         lower_ci = exp(estimate - 1.96*std.error),
         upper_ci = exp(estimate + 1.96*std.error)) %>%
  select(city_state, term, OR, lower_ci, upper_ci)

cities_glm
```

Plot that shows estimated ORs and CIs for each city.
```{r}
cities_glm%>%
  filter(term == "victim_sexMale")%>%
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() + 
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci)) +
  labs(y = "OR", x = "City, State",title = "Homicides")+
   theme(axis.text.x = element_text(angle = 80, hjust = 1))
```

In most states, the odds that the homicide will remain solved for cases where the victim is male is lower than the odds that the homicide will remain solved for cases where the victim is female (ex: Chicago, Cincinnati, Detroit)


# Problem 3

Load and clean data for regression analysis
```{r}
birthweight_data =
  read_csv("./data/birthweight.csv") %>% 
  drop_na() %>% 
  janitor::clean_names()

#checking datatype
  str(birthweight_data)

birthweight_df =
  birthweight_data%>%
  mutate(
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    frace = as.factor(frace),
    frace = recode_factor(frace,
                      "1" = "White",
                      "2" = "Black",
                      "3" = "Asian",
                      "4" = "Puerto Rican",
                      "8" = "Other"),
    mrace = as.factor(mrace),
    mrace = recode_factor(mrace,
                      "1" = "White",
                      "2" = "Black",
                      "3" = "Asian",
                      "4" = "Puerto Rican",
                      "8" = "Other")
  )%>%
  select(bwt,everything())
  
```

Propose regression model for birthweight
```{r}
#checking assumption-normal distribution and residuals
birthweight_df %>% 
  ggplot(aes(x = bwt)) + 
  geom_histogram(binwidth = 25) + 
  labs(
    title = "Checking Assumption", x = "Birthweight (g)",y = "Count"
  )

#I excluded pnumlbw and pnumgsa because they have 0 observations, malform and parity because they have low cell count, and ppbmi because I can use ppwt instead.
full_model = 
  lm(
    bwt ~ babysex + bhead + blength + delwt+ fincome+frace + gaweeks + menarche+ mheight + momage + mrace + smoken + ppwt + wtgain,
    data = birthweight_df
  )

#Summary table to see which covariates have p<0.05
summary(full_model) %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value)%>% 
   mutate(
    p_value = format.pval(p.value, digits = 3, eps = 0.05)
  ) %>% 
  select(-p.value) %>%
  arrange(p_value) %>% 
  knitr::kable()
```

Variables that I found significant were babysex, bhead, blength, delwt, gaweeks, 
mheight, mraceBlack, smoken, and ppwt. 

```{r}
reduced_model = 
  lm(
    bwt ~ babysex + bhead + blength + delwt+ gaweeks +  mheight + mrace + smoken + ppwt,
    data = birthweight_df
  )

birthweight_df %>% 
  add_predictions(reduced_model) %>% 
  add_residuals(reduced_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point()+
  labs(
    title = "Residuals against Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  )

```

Based on this plot, there seems to be a violation of the assumption of constance variance. There are some outliers that needs to be taken care of, and the distribution is heavily left-skewed. Possible solutions might be creating formal rule to exclude outliers, transforming variable using log transformation, or selecting best models of subsets by maximizing adjusted R-squared and minimizing prediction error. 


Alternative Models
```{r}
alt_model1 =
  lm(bwt ~ blength + gaweeks, data = birthweight_df)

alt_model2 = 
  lm(bwt ~ bhead + blength + babysex + bhead*blength + blength*babysex + bhead*babysex + bhead*blength*babysex, data = birthweight_df)
```

Compare models using cross-validation
```{r}
cv_df = 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df =
  cv_df %>% 
  mutate(
    reduced_model = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + delwt+ gaweeks +  mheight + mrace + smoken + ppwt, data = .x)),
    alt_model1 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    alt_model2 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + blength*babysex + bhead*babysex + bhead*blength*babysex, data = .x))
  ) %>% 
  mutate(
    rmse_reduced_model = map2_dbl(.x = reduced_model, .y = test, ~rmse(model = .x, data = .y)),
    rmse_alt1 = map2_dbl(.x = alt_model1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_alt2 = map2_dbl(.x = alt_model2, .y = test, ~rmse(model = .x, data = .y))
  )

  cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot()

```
From the graph, we can clearly see that my reduced model has the lowest mean rmse value and therfore, might be the best fit among these three models.


